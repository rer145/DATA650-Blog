setwd("C:/Users/ronri/OneDrive/Mercyhurst/DATA 650 - Comm & Collab DS/blog")
blogdown:::new_post_addin()
build_site()
library(blogdown)
build_site()
serve_site()
library(dplyr)
library(tidytext)
library(wordcloud)
library(stringr)
library(gutenbergr)
gutenberg_works(title=='Burnt Offerings')  #id 345
gutenberg_works(str_detect(title, 'Burnt Offerings'))
gutenberg_works(str_detect(title, 'Frankenstein'))
gutenberg_works(str_detect(title, 'Burnt Offerings'))
gutenberg_works(str_detect(title, 'Exorcist'))
??gutenberg_works
gutenberg_works(str_detect(title, 'The Trial'))
gutenberg_works(str_detect(title, 'Metamorphisis'))
gutenberg_works(str_detect(title, 'Metamorphosis'))
gutenberg_works(str_detect(author, 'Kafka'))
gutenberg_works(str_detect(title, 'Jekyll'))
jh<-gutenberg_download(42)
View(jh)
jh<-gutenberg_download(42, strip=TRUE)
View(jh)
jh%>%
count(title)
View(jh)
str_detect(jh$text, "^\d)")
str_detect(jh$text, "^\\d{2})$")
str_detect(jh$text, "^\\d{2}\)$")
str_detect(jh$text, "^\\d{2}$")
str_detect(jh$text, "^\\d$")
str_detect(jh$text, "^\\d+\\)")
jh%>%
filter(str_detect(jh$text, "^\\d+\\)")
jh%>%
filter(str_detect(jh$text, "^\\d+\\)")
jh%>%
filter(str_detect(jh$text, "^\\d+\\)"))
jh%>%
filter(str_detect(jh$text, "^\\d+\\)")==TRUE)
chapters<-jh%>%
filter(str_detect(jh$text, "^\\d+\\)")==TRUE)
View(chapters)
jh<-jh%>%
filter(str_detect(jh$text, "^\\d+\\)")==FALSE)
View(jh)
jh<-jh[14:]
jh<-jh[14:dim(jh),]
View(jh)
tail(jh)
words<-jh%>%
unnest_tokens(word, text)
words<-words%>%
filter(!(word%in%stop_words$word))
View(words)
freq<-words%>%
group_by(word)%>%
summarize(count=n())
View(freq)
wordcloud(freq$word, freq$count, min.freq=50, max.words=100)
wordcloud(freq$word, freq$count, max.words=50)
wordcloud(freq$word, freq$count, max.words=100)
head(jh)
print(jh, n=20)
jh<-gutenberg_download(42, strip=TRUE)
print(jh, n=20)
library(dplyr)
library(tidytext)
library(wordcloud)
library(stringr)
library(gutenbergr)
gutenberg_works(str_detect(title, 'Jekyll')) #id 42
jh<-gutenberg_download(42, strip=TRUE)
jh<-gutenberg_download(42, strip=TRUE)
View(jh)
jh<-gutenberg_download(42, strip=TRUE)
words<-jh%>%
unnest_tokens(word, text)
words<-words%>%
filter(!(word%in%stop_words$word))
freq<-words%>%
group_by(word)%>%
summarize(count=n())
wordcloud(freq$word, freq$count, max.words=100)
